{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c423b6864af4915944570c2c11f047a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_106c698e05084b639cb07f062861d7a4",
              "IPY_MODEL_904c9bac00314248bc34ededa5569041",
              "IPY_MODEL_1c8f6c6de5144bc686bd2ee8a2b1a3fe"
            ],
            "layout": "IPY_MODEL_75196d51cc7b41b0a872e7891263e045"
          }
        },
        "106c698e05084b639cb07f062861d7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_290b4ea2eb0d4545a2ac3cd4285d969d",
            "placeholder": "​",
            "style": "IPY_MODEL_ab13fa15f4d14fdab09952f77e2f90c3",
            "value": "Epoch 19: 100%"
          }
        },
        "904c9bac00314248bc34ededa5569041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e968ad93f3e84f3d8e212bf40a106a67",
            "max": 430,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ef80a33fb5f4ea8a8cd17b46455c475",
            "value": 430
          }
        },
        "1c8f6c6de5144bc686bd2ee8a2b1a3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c70136c541b4fe6ac98e7ce400e1ccc",
            "placeholder": "​",
            "style": "IPY_MODEL_e59eccfa99ee4a2eb598a7c639b4509d",
            "value": " 430/430 [00:16&lt;00:00, 25.56it/s, v_num=4]"
          }
        },
        "75196d51cc7b41b0a872e7891263e045": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "290b4ea2eb0d4545a2ac3cd4285d969d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab13fa15f4d14fdab09952f77e2f90c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e968ad93f3e84f3d8e212bf40a106a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ef80a33fb5f4ea8a8cd17b46455c475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c70136c541b4fe6ac98e7ce400e1ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e59eccfa99ee4a2eb598a7c639b4509d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning # To make code shorter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vESfQJ3t74RJ",
        "outputId": "2b50aaae-3e90-450c-86ba-37f1889c450c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.2.5-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch_lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pytorch_lightning-2.2.5 torchmetrics-1.4.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooA7MgLM5dl_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import MNIST\n",
        "import matplotlib.pyplot as plt\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
        "NUM_WORKERS = int(os.cpu_count()/2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, data_dir = \"./data\", batch_size = BATCH_SIZE, num_workers = NUM_WORKERS):\n",
        "    super().__init__()\n",
        "    self.data_dir = data_dir\n",
        "    self.batch_size = batch_size\n",
        "    self.num_workers = num_workers\n",
        "    self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "        ])\n",
        "  def prepare_data(self):\n",
        "    MNIST(self.data_dir, train = True, download = True)\n",
        "    MNIST(self.data_dir, train = False, download = True)\n",
        "\n",
        "  def setup(self, stage = None):\n",
        "    # Assign train/val datasets\n",
        "    if stage== \"fit\" or stage is None:\n",
        "      mnist_full = MNIST(self.data_dir, train= True, transform = self.transform)\n",
        "      self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
        "    if stage ==\"test\" or stage is None:\n",
        "      self.mnist_test = MNIST(self.data_dir, train= False, transform = self.transform)\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.mnist_train, batch_size = self.batch_size, num_workers = self.num_workers)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.mnist_val, batch_size = self.batch_size, num_workers = self.num_workers)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.mnist_test, batch_size = self.batch_size, num_workers = self.num_workers)\n"
      ],
      "metadata": {
        "id": "DqMUuhpk8fcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detective: fake or real --> 1 output[0,1]\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 1) # 1 ; the only output\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "\n",
        "    # Flatten the tensor so it can be fed into the FC layers\n",
        "    x = x.view(-1,320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training = self.training)\n",
        "    x = self.fc2(x)\n",
        "    return torch.sigmoid(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Th60xHsxEdQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Fake Data : Output like real data [1,28,28] and values -1,1\n",
        "# Based on latent_dim value, we upsample an outpit that is in the shape of original images [1,28,28] and values -1,1\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, latent_dim):\n",
        "    super().__init__()\n",
        "    self.lin1 = nn.Linear(latent_dim, 7*7*64) # [n,256, 7,7]\n",
        "    self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride = 2) # [n, 64, 16, 16]\n",
        "    self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride = 2) # [n, 16, 34, 34]\n",
        "    self.conv = nn.Conv2d(16, 1, kernel_size = 7) # [n, 1, 28, 28]\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Pass latent space input into linear layer and reshape\n",
        "    x = self.lin1(x)\n",
        "    x = F.relu(x)\n",
        "    x = x.view(-1, 64, 7, 7) # 256\n",
        "\n",
        "    # Upsample (transposed conv) 16x16 (64 feature maps)\n",
        "    x = self.ct1(x)\n",
        "    x = F.relu(x)\n",
        "    # Upsample to 34x34 (16 feature maps)\n",
        "    x = self.ct2(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # Convolution to 28x28(1 feature map)\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "EQ6vwdaKKt0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GAN(pl.LightningModule):\n",
        "    def __init__(self, latent_dim=100, lr=0.0002):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.generator = Generator(latent_dim=self.hparams.latent_dim)\n",
        "        self.discriminator = Discriminator()\n",
        "        self.validation_z = torch.randn(6, self.hparams.latent_dim)\n",
        "        self.automatic_optimization = False  # Enable manual optimization\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.generator(z)\n",
        "\n",
        "    def adversarial_loss(self, y_hat, y):\n",
        "        return F.binary_cross_entropy(y_hat, y)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        real_imgs, _ = batch\n",
        "        opt_g, opt_d = self.optimizers()  # Access optimizers\n",
        "\n",
        "        # Sample noise\n",
        "        z = torch.randn(real_imgs.shape[0], self.hparams.latent_dim).type_as(real_imgs)\n",
        "\n",
        "        # Train Generator: max log(D(G(z)))\n",
        "        fake_imgs = self(z)  # Generate fake images\n",
        "        y_hat = self.discriminator(fake_imgs)\n",
        "        y = torch.ones(real_imgs.size(0), 1).type_as(real_imgs)\n",
        "        g_loss = self.adversarial_loss(y_hat, y)\n",
        "\n",
        "        # Optimize Generator\n",
        "        opt_g.zero_grad()\n",
        "        self.manual_backward(g_loss)\n",
        "        opt_g.step()\n",
        "\n",
        "        # Train Discriminator: max log D(x) + log (1 - D(G(z)))\n",
        "        y_hat_real = self.discriminator(real_imgs)\n",
        "        y_real = torch.ones(real_imgs.size(0), 1).type_as(real_imgs)\n",
        "        real_loss = self.adversarial_loss(y_hat_real, y_real)\n",
        "\n",
        "        y_hat_fake = self.discriminator(fake_imgs.detach())\n",
        "        y_fake = torch.zeros(real_imgs.size(0), 1).type_as(real_imgs)\n",
        "        fake_loss = self.adversarial_loss(y_hat_fake, y_fake)\n",
        "\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        # Optimize Discriminator\n",
        "        opt_d.zero_grad()\n",
        "        self.manual_backward(d_loss)\n",
        "        opt_d.step()\n",
        "\n",
        "        log_dict = {\"g_loss\": g_loss, \"d_loss\": d_loss}\n",
        "        self.log_dict(log_dict)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        lr = self.hparams.lr\n",
        "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr)\n",
        "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr)\n",
        "        return [opt_g, opt_d]\n",
        "\n",
        "    def plot_imgs(self):\n",
        "        z = self.validation_z.type_as(self.generator.model[0].weight)\n",
        "        sample_imgs = self(z).cpu()\n",
        "\n",
        "        print(\"epoch\", self.current_epoch)\n",
        "        fig = plt.figure()  # Fixed typo: fiqure -> figure\n",
        "        for i in range(sample_imgs.size(0)):\n",
        "            plt.subplot(2, 3, i + 1)\n",
        "            plt.tight_layout()\n",
        "            plt.imshow(sample_imgs.detach()[i, 0, :, :], cmap=\"gray_r\", interpolation=\"none\")\n",
        "            plt.title(\"Generated Data\")\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            plt.axis(\"off\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "QGEvETJJvcu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Module = MNISTDataModule()\n",
        "model = GAN()"
      ],
      "metadata": {
        "id": "yaOy9ldIe_96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.plot_imgs"
      ],
      "metadata": {
        "id": "nPPRk6WvfL4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(max_epochs = 20, devices = AVAIL_GPUS)\n",
        "trainer.fit(model,Data_Module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "1c423b6864af4915944570c2c11f047a",
            "106c698e05084b639cb07f062861d7a4",
            "904c9bac00314248bc34ededa5569041",
            "1c8f6c6de5144bc686bd2ee8a2b1a3fe",
            "75196d51cc7b41b0a872e7891263e045",
            "290b4ea2eb0d4545a2ac3cd4285d969d",
            "ab13fa15f4d14fdab09952f77e2f90c3",
            "e968ad93f3e84f3d8e212bf40a106a67",
            "8ef80a33fb5f4ea8a8cd17b46455c475",
            "9c70136c541b4fe6ac98e7ce400e1ccc",
            "e59eccfa99ee4a2eb598a7c639b4509d"
          ]
        },
        "id": "sLbdErwpfak_",
        "outputId": "ddb7b244-571c-4cfa-e067-7364ba7f3ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name          | Type          | Params\n",
            "------------------------------------------------\n",
            "0 | generator     | Generator     | 358 K \n",
            "1 | discriminator | Discriminator | 21.4 K\n",
            "------------------------------------------------\n",
            "379 K     Trainable params\n",
            "0         Non-trainable params\n",
            "379 K     Total params\n",
            "1.520     Total estimated model params size (MB)\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c423b6864af4915944570c2c11f047a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n"
          ]
        }
      ]
    }
  ]
}